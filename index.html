<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="OF6eNVbi70EpNXMFjlTzBsbiZG8lCTgXWFapE0HfTi4" />

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yukun Xia</title>
    <meta name="author" content="Yukun  Xia" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://yukunxia.github.io/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://yukunxia.github.io/">Yukun Xia</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/life/">Life</a>
              </li>
<!-- fixed links -->
              <li class="nav-item">
                <a class="nav-link" href="https://www.linkedin.com/in/yukun-xia/" target="_blank" rel="noopener noreferrer"> Linkedin
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="https://github.com/YukunXia" target="_blank" rel="noopener noreferrer"> Github
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="https://www.youtube.com/channel/UCXVYgKqIpjD9K2MNLoNvwFA" target="_blank" rel="noopener noreferrer"> YouTube
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="/assets/pdf/yukun_resume.pdf"> Resume </a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>

      <style>
        .gitter-chat-embed {
          margin-top: 57px;
        }
      </style>

      <script>
        ((window.gitter = {}).chat = {}).options = {
          room: 'YukunXia/yukunxia.github.io'
        };
      </script>
      <script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           Yukun Xia
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-right">
<figure>

  <picture>
    <!-- <source media="(max-width: 480px)" srcset="/assets/img/profile-pic-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/profile-pic-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/profile-pic-1400.webp" />
    -->

    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded" src="/assets/img/profile-pic.jpg" alt="profile-pic.jpg">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

<p>Hi there, I’m a robotics software engineer, graduating from CMU in May 2022. Here’s a brief self-intro.</p>

<p>On the tech side, I’m enthusiastic about every technology to bridge the virtual and the real world. Robotics is all about that. Although most of my current interests stay with SLAM, geometry, and 3D vision, I won’t resist learning and practicing on any other robotics topic.</p>

<p>As for my personality, I’m always fascinated by the opportunities to build systems from scratch and witness the real applications. I love challenges and I believe one of the meanings of life come from the efforts to challenge our limits. Every time I step out of my comfort zone, my knowledge and capability expand significantly.</p>

<!-- <p align="center">
  <a href="mailto:%79%75%6B%75%6E%78%69%61%32%30%32%30@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://github.com/YukunXia" title="GitHub"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/yukun-xia" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
            <a href="https://yukunxia.github.io/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a>
            
</p> -->

<p><br></p>

<hr>

<p><br></p>

<h1 id="projects">Projects</h1>

<h2 id="digital-twin-an-open-source-solution">Digital Twin: An Open Source Solution</h2>

<p><em>I did this project mainly for fun. NeRF is quite capable, and only needs a camera, but the objects in NeRF are not arbitrarily deformable after training. Meanwhile, many AI body pose estimators are available online, requiring only a camera as well. Blender is a free and open-source 3D modeling software. So my question was: can we combine them together? Now the answer is “Yes!”</em></p>

<ul>
  <li>Created my own digital twin with a cellphone camera and some open-source software</li>
  <li>Calibrated my camera, took body pictures, estimated camera poses in COLMAP, and trained a NeRF model</li>
  <li>Cleaned, simplified and smoothed the mesh extracted from NeRF in Blender</li>
  <li>Built pose bones and assigned the corresponding patches of the mesh in Blender</li>
  <li>Extracted target body poses from an online dancing video using MediaPipe, and animated my digital twin to imitate the dancing gestures</li>
</ul>

<p align="center">
  <iframe src="https://www.youtube.com/embed/NvI3KYCf9A0" width="480" height="360" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p><a href="https://github.com/YukunXia/Digital-Twin-An-Open-Source-Solution" target="_blank" rel="noopener noreferrer">Source Code</a></p>

<h2 id="an-empirical-study-on-multi-view-reconstruction-methods">An Empirical Study on Multi-View Reconstruction Methods</h2>

<p>Mar 2022 - Apr 2022</p>

<p>Collaborator: Yuqing Qin</p>

<ul>
  <li>Course project for 16-889 “Learning for 3D Vision”</li>
  <li>Quantitatively and qualitatively compared dense multi-view reconstruction quality of COLMAP, MVSNet and NeRF in customized challenging scenes</li>
  <li>Stored some of our CMU memories into neural represented 3D worlds
    <ul>
      <li>“DD Arm” locates on the 4th floor of Newell-Simon Hall, next to the bridge to Wean Hall</li>
      <li>“Lion” records one of the two lion statues on <a href="https://www.google.com/maps/@40.4450345,-79.942756,3a,75y,104.06h,87.19t/data=!3m6!1e1!3m4!1sNjAJIfiUBCsCBmWH6BnnBA!2e0!7i16384!8i8192" target="_blank" rel="noopener noreferrer">1060 Morewood Ave</a>. Many people know that the fence is regularly repainted, but these two lions change their appearances very often as well.</li>
    </ul>
  </li>
</ul>

<p align="center">
    <img src="/assets/img/projects/multi-view-reconstruction-methods-00.png" width="500">
    <figcaption align="center">
      <b> Sample results in the first three scenes </b>
    </figcaption>
</p>

<p><a href="https://drive.google.com/file/d/1mGUzMCABiEHSW0bTtk_dl6TKVJk_pyuT/view?usp=sharing" target="_blank" rel="noopener noreferrer">Report PDF</a></p>

<h2 id="autonomous-mapping-and-exploration-in-a-simulated-farmland">Autonomous Mapping and Exploration in a Simulated Farmland</h2>

<p>Mar 2022 - Apr 2022</p>

<p>Collaborator: Calen Robinson</p>

<ul>
  <li>Course project for 16765-A “Special Topics: Robotics &amp; AI for Agriculture”</li>
  <li>Built a farmland simulation environment and tested autonomous exploration with a Clearpath Husky robot and a 3D lidar</li>
  <li>Implemented the frontier detection algorithm to determine the next best goal</li>
  <li>Implemented and optimized the pure pursuit algorithm to enable agile motions and faster failure recovery</li>
  <li>Used Octomap to store the 3D map and extract the 2D occupancy grid</li>
  <li>Compared the exploration efficiency of different lidar configurations</li>
</ul>

<p align="center">
    <img src="/assets/img/projects/farmland-exploration-00.png" width="600">
    <figcaption align="center">
      <b> Our final project poster </b>
    </figcaption>
</p>

<p align="center">
  <iframe src="https://www.youtube.com/embed/yeF6xDfmzNk" width="480" height="360" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p><a href="https://github.com/YukunXia/Farmland-Exploration" target="_blank" rel="noopener noreferrer">Source Code</a></p>

<h2 id="deployment-of-superpoint-on-jetson-nano">Deployment of SuperPoint on Jetson Nano</h2>

<p>Oct 2021 - Dec 2021</p>

<p>Collaborator: Yuqing Qin</p>

<ul>
  <li>Course project for 11-767 “On-Device Machine Learning”</li>
  <li>Retrained SuperPoint models with different configurations, deployed them on a Jetson Nano</li>
  <li>Tested the trade-off between performance and energy efficiency on the KITTI dataset</li>
</ul>

<p align="center">
    <img src="/assets/img/projects/superpoint-00.png" width="400">
    <figcaption align="center">
      <b> System diagram </b>
    </figcaption>
</p>

<p align="center">
    <img src="/assets/img/projects/superpoint-01.png" width="500">
    <figcaption align="center">
      <b> One of our superpoint models tracking interframe keypoint motions in the KITTI dataset </b>
    </figcaption>
</p>

<p><a href="https://github.com/YukunXia/SuperPoint-Stereo-Visual-Odometry" target="_blank" rel="noopener noreferrer">Source Code</a></p>

<p><a href="https://github.com/YukunXia/SuperPoint-Stereo-Visual-Odometry/blob/test_two_batches/ODML_project_report.pdf" target="_blank" rel="noopener noreferrer">Report PDF</a></p>

<h2 id="mobile-robot-object-classiﬁcation--avoidance">Mobile Robot Object Classiﬁcation &amp; Avoidance</h2>

<p>Oct 2020 - Nov 2021</p>

<p>Collaborator: Calen Robinson, Gitaek Lee, Jinkun Liu, Thomas Xu</p>

<ul>
  <li>This is a team capstone project, sponsored by Omron Robotics</li>
  <li>Conducted Agile teamwork and developed ROS programs in C++</li>
  <li>Built a factory simulation environment in Gazebo with mobile robots, forklifts and pedestrians</li>
  <li>Trained YOLOv5 and deployed the model onto Jetson AGX Xavier via TensorRT, reaching 50FPS</li>
  <li>Calibrated camera-lidar-robot extrinsics with nonlinear least square solvers</li>
  <li>Estimated object locations by fusing image object detection and lidar point cloud</li>
  <li>Set up a ground truth system to evaluate the performance of object detection models and the sensor fusion algorithm</li>
</ul>

<p><a href="https://mrsdprojects.ri.cmu.edu/2021teamd/" target="_blank" rel="noopener noreferrer">Website</a></p>

<h2 id="reimplementation-of-v-loam">Reimplementation of V-LOAM</h2>

<p>Mar 2021 - May 2021</p>

<p>Collaborator: Ivan Cisneros, Shuqin Xie, Xinjie Yao</p>

<ul>
  <li>Course project for 16-833 “Robot Localization and Mapping”</li>
  <li>Extracted and matched features from images; estimated continuous depth map from point cloud; optimized frame-to-frame motion with Ceres</li>
  <li>Refactored A-LOAM to integrate with visual odometry and enabled more controllable intermodular communication</li>
  <li>Reduced translation and rotation error of A-LOAM respectively by 26.9% and 22.5% in 9 KITTI sequences in average</li>
</ul>

<p align="center">
  <iframe src="https://www.youtube.com/embed/NnoxB3r_cDM" width="480" height="360" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p><a href="https://github.com/YukunXia/VLOAM-CMU-16833" target="_blank" rel="noopener noreferrer">Source Code</a></p>

<p><a href="https://github.com/YukunXia/VLOAM-CMU-16833/blob/master/16833_report_V2.pdf" target="_blank" rel="noopener noreferrer">Report PDF</a></p>

<h2 id="dense-slam-with-point-based-fusion">Dense SLAM with Point-Based Fusion</h2>

<p>Apr 2021 - Apr 2021</p>

<ul>
  <li>One of the assignments of 16-833 “Robot Localization and Mapping”. <em>Its scale is not as large as other projects here, but the topic is pretty relevant</em>
</li>
  <li>Used projective data association between RGBD frames for fast ICP, and reconstructed dense map through local point fusion</li>
  <li>The dataset is ICL-NUIM</li>
</ul>

<p align="center">
    <img src="/assets/img/projects/dense-slam-00.png" width="500">
    <figcaption align="center">
      <b> A reconstructed scene</b>
    </figcaption>
</p>

<h2 id="autonomous-exploration-development-environment">Autonomous Exploration Development Environment</h2>

<p>Sept 2020 - January 2021</p>

<p>Independent Study Advised by Ji Zhang</p>

<ul>
  <li>Built a dense resonctruction of CMU campus to test robot exploration algorithms</li>
  <li>Refined simulation environments in Blender</li>
  <li>Wrote a literature review for multiple robot exploration</li>
</ul>

<p align="center">
    <img src="/assets/img/projects/ground-based-autonomy-00.png" width="500">
    <figcaption align="center">
      <b> The reconstructed CMU campus</b>
    </figcaption>
</p>

<p><a href="https://www.cmu-exploration.com/" target="_blank" rel="noopener noreferrer">Project Website</a></p>

<h2 id="real-time-mpc-with-ilqr-for-self-driving-in-carla">Real-time MPC with iLQR for Self-Driving in Carla</h2>

<p>Apr 2020 - Jun 2020</p>

<ul>
  <li>Learned the vehicle dynamical model by combining the bicycle model and neural network</li>
  <li>Implemented the iLQR algorithm from scratch with Google Jax</li>
  <li>Leveraged the log-sum-exp trick to approximate the true distance function in the waypoint following task, avoiding deviations at the sharp turn.</li>
  <li>Validated the real-time performance of MPC algorithm in Carla, with iLQR potentially running in 1kHz</li>
</ul>

<p align="center">
  <iframe src="https://www.youtube.com/embed/AEuxxsT1zcI" width="480" height="360" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p><a href="https://github.com/YukunXia/Carla_iLQR_MPC" target="_blank" rel="noopener noreferrer">Source Code</a></p>

<h2 id="lqr-funnel-graph-for-kinodynamic-planning">LQR Funnel Graph for Kinodynamic Planning</h2>

<p>Mar 2020 - May 2020</p>

<ul>
  <li>Course project for 6.832 “Underactuated Robotics”</li>
  <li>Generated trajectories in the state space of a single pendulum through trajectory optimization</li>
  <li>Used Sum-of-Square Programming to calculate the region of attraction (RoA) along the trajectories, in the shape of funnels</li>
  <li>Practiced the kinodynamic planning through Depth First Search on the precomputed funnel graph</li>
</ul>

<p align="center">
  <iframe src="https://www.youtube.com/embed/MIZTSZ0CJZA" width="480" height="360" frameborder="0" allowfullscreen="">
  </iframe>
</p>

<p><br></p>

<hr>

<p><br></p>

          </div>

          
          
          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%79%75%6B%75%6E%78%69%61%32%30%32%30@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://github.com/YukunXia" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/yukun-xia" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://yukunxia.github.io/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a>
            
            </div>

            <div class="contact-note">
              
            </div>
            
          </div>
        </article>

      </div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2022 Yukun  Xia. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

